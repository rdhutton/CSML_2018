{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03-JUL-18\n",
    "\n",
    "Adaptation of \"LIME - basic LR\"\n",
    "\n",
    "Trains on the hyperpartisan data\n",
    "\n",
    "Tests on annotated data from Briefr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/rick/factmata/factnlp-experimental/lime')\n",
    "\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/rick/factmata/factmata-quality-engine/factnlp')\n",
    "sys.path.append('/Users/rick/factmata/utils')\n",
    "sys.path.append('/Users/rick/factmata/fastText')\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"'pattern' package not found; tag filters are not available for English\", \"log_timestamp\": \"2018-09-07 09:20:14.696441\", \"filename\": \"textcleaner.py\", \"function\": \"<module>\", \"path\": \"/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/gensim/summarization/textcleaner.py\", \"logger_name\": \"summarizer.preprocessing.cleaner\", \"lineno\": 37, \"process\": 46898, \"thread\": 140736053298048, \"details\": {}}\n"
     ]
    }
   ],
   "source": [
    "from factnlp.category.category_predictor import CategoryPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"Loading models\", \"log_timestamp\": \"2018-09-07 09:20:17.201393\", \"filename\": \"tasks.py\", \"function\": \"models_loader_factory\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/distributor/tasks.py\", \"logger_name\": \"distributor.tasks\", \"lineno\": 53, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"Loading models\"}}\n",
      "{\"level\": \"INFO\", \"message\": \"Loading models\", \"log_timestamp\": \"2018-09-07 09:20:17.204148\", \"filename\": \"tasks.py\", \"function\": \"models_loader_factory\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/distributor/tasks.py\", \"logger_name\": \"distributor.tasks\", \"lineno\": 53, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"Loading models\"}}\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "import distributor.tasks\n",
    "models = distributor.tasks.models_loader_factory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google drive paths\n",
    "\n",
    "labelled_data_path = '/hyperpartisanship/CF labelled data'\n",
    "training_data_path = '/Users/mariarmestre/Projects/factnlp/models/hyperpartisanship/current/'\n",
    "\n",
    "output_data_path = '/hyperpartisanship/error analysis/with CF labelled data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"Loading Politics Classifier Model\", \"log_timestamp\": \"2018-09-07 09:20:17.217199\", \"filename\": \"modelsloader.py\", \"function\": \"__load_hyperpartisanship_model\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/modelsloader.py\", \"logger_name\": \"factnlp\", \"lineno\": 72, \"process\": 46898, \"thread\": 140736053298048, \"details\": {}}\n",
      "{\"level\": \"INFO\", \"message\": \"Loading Hyperpartisanship Model\", \"log_timestamp\": \"2018-09-07 09:21:02.288272\", \"filename\": \"modelsloader.py\", \"function\": \"__load_hyperpartisanship_model\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/modelsloader.py\", \"logger_name\": \"factnlp\", \"lineno\": 74, \"process\": 46898, \"thread\": 140736053298048, \"details\": {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<factnlp.hyperpartisanship.hyperpartisanship_predictor.HyperpartisanshipPredictor at 0x158e3e278>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Production model\n",
    "\n",
    "production_hp = models.get_hyperpartisanship_model()\n",
    "production_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function to provide predict_proba() for LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc func to serve as predict_proba() for LIME\n",
    "import json\n",
    "classes = ['Biased','Unbiased']\n",
    "\n",
    "def fm_predict_proba(in_text_list,verbose=False):\n",
    "  \"\"\"\n",
    "  Takes a list of texts and for each gets a probability of being hyperpartisan from the hyperpartisan model\n",
    "  Then extends the probability returned into a tuple of (probability of true, probability of false) as required\n",
    "  by the LIME explain.explainer_instance function\n",
    "  \n",
    "  Args:\n",
    "    list of texts represented as strings - prediction will be run against each \n",
    "  \n",
    "  Returns:\n",
    "    numpy array of tuples - each represents (p(is hyperpartisan),p(is not hyperpartisan))\n",
    "  \"\"\"\n",
    "  \n",
    "  probs = []\n",
    "  if verbose:\n",
    "    print(\"base text length =\", len(in_text_list[0]))\n",
    "    print(\"fm_predict_proba - number of elements in text list \", len(in_text_list))\n",
    "  text_list = in_text_list\n",
    "  prob1 = prob2 = 0 \n",
    "  t0 = time.time()\n",
    "#   call to hyperpartisan classifier\n",
    "  results = production_hp.predict(text_list)\n",
    "  t1 = time.time()\n",
    "\n",
    "  if verbose:\n",
    "    print(\"predict run time = \",str(datetime.timedelta(seconds=round(t1-t0,0))))\n",
    "  for result in results :  \n",
    "    if result['class'] == classes[0]:\n",
    "      prob1 = result['score']\n",
    "      prob2 = 1 - prob1\n",
    "    else: \n",
    "      prob2 = result['score']\n",
    "      prob1 = 1 - prob2\n",
    "    probs.append([prob1,prob2])\n",
    "    \n",
    "  return(np.array(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.083, 0.917]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick test if needed\n",
    "test_txt1 = []\n",
    "test_txt1.append(\"President Donald Trump was in the Philippines on Monday as part of the final stop on a whirlwind, 12-day tour of Asia that included warm receptions by the gracious hosts of Japan, South Korea, China and Vietnam, according to Fox News.\")\n",
    "res = fm_predict_proba(test_txt1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data, train a simple LR classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# test_file = \"/Users/rick/factmata/article quotes v2.csv\"\n",
    "test_file = \"/Users/rick/factmata/article quotes - 2018-08-09.csv\"\n",
    "\n",
    "# training = pd.read_csv(\"/Users/rick/factmata/train.csv\")\n",
    "training = pd.read_csv(\"/Users/rick/factmata/factmata-quality-engine/factnlp/models/hyperpartisanship/current/train.csv\")\n",
    "\n",
    "testing = pd.read_csv(test_file)\n",
    "class_names = ['Biased','Unbiased']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(training['text'])\n",
    "train_targets = training['tag']\n",
    "test_vectors = vectorizer.transform(testing['text'])\n",
    "test_targets = testing['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_neutral_tags = ['agree','citation_needed','fair','funny','question']\n",
    "bad_tags = ['one_sided',\"unfair\",\"wrong\",\"nasty\"]\n",
    "biased_tags = ['one_sided']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(C=1e5)\n",
    "lr.fit(train_vectors,train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an explainer object \n",
    "Select text and run explainer\n",
    "Create list of explainer words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = testing['id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which model to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MODEL = 0\n",
    "FM_MODEL = 1 \n",
    "\n",
    "# model_used = LR_MODEL\n",
    "model_used = FM_MODEL\n",
    "\n",
    "if model_used == FM_MODEL : \n",
    "  pred_proba_func = fm_predict_proba\n",
    "  num_samples = 1000\n",
    "else :\n",
    "  pred_proba_func = c.predict_proba\n",
    "  num_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  function to return all rows (i.e. annotations) matching a page_id\n",
    "def get_quotes_list(testing, page_id):\n",
    "  \"\"\"\n",
    "   Args:\n",
    "     testing: panda data frame with text, quotes etcx\n",
    "     page_id: id of piece of text (as represented in 'page__id' of data frame)\n",
    "   \n",
    "   Returns:\n",
    "     List of all rows in data frame that match page_id (i.e. all rows which represent\n",
    "     quotes from this piece of text)\n",
    "  \"\"\"\n",
    "\n",
    "#   TODO improve error handling ?\n",
    "#   if page_id not in testing['page__id']:\n",
    "#     return [] \n",
    "  page_refs = (testing['page__id'] == page_id)\n",
    "#   for df in testing[page_refs]:\n",
    "#     print(\"page_id , quote tag \",df['page__id'] ,df['tag'])\n",
    "#     if testing[page_ref]['tag'] in biased_tags:\n",
    "#       pages_list.append[page_ref]\n",
    "#     else:\n",
    "#       print(\"get quotes - reject \", page_ref, testing[page_ref]['tag'])\n",
    "\n",
    "  pages_list = testing[page_refs]\n",
    "\n",
    "  print(\"pre-filter\",page_id,pages_list['tag'])\n",
    "  pages_list = pages_list[pages_list['tag'] == \"one_sided\"]\n",
    "  print(\"post-filter\",page_id,pages_list['tag'])\n",
    "#   print(\"pages list = \", pages_list['tag'])\n",
    "\n",
    "  return pages_list\n",
    "\n",
    "def get_word_scores(word_list, text, text_as_dict, quotes_region): \n",
    "  \"\"\"\n",
    "  Produces score on how often the words appear in the text and in the quotes region\n",
    "  (Simpler version of get_word_stats, which uses a list of quotes rather than unified\n",
    "  quote regions)\n",
    "\n",
    "  Args:\n",
    "    words: a subset of words or ngrams from the text \n",
    "    text : the text itself\n",
    "    text_as_dict:  dict with key as a word and value its occurence count e.g {'fall':3}\n",
    "    quotes_region : list of tuples in form (start, stop) indicating position of quote regions in text\n",
    "\n",
    "  Returns: Dict - key is word, value is dict with annt_count - no of occurences of word in quote region\n",
    "                                                  text_count - no of occurences of word in entire text \n",
    "                                \n",
    "  \"\"\"\n",
    "  \n",
    "  debug_list = [(start,stop) for (start,stop) in quotes_region]\n",
    "#   print(\"quotes region = \", sorted(quotes_region))\n",
    "  all_quotes = ' '.join([text[start:stop] for (start,stop) in quotes_region])\n",
    "  all_quotes_count_dict = Counter(np.array(re.split(r'%s|$' % r'\\W+' , all_quotes)))\n",
    "  scores = {word:{'annt_count':0,\n",
    "                 'text_count':0,\n",
    "                  'weight':weight\n",
    "                } for (word,weight) in word_list}\n",
    "  for word,_ in word_list:  \n",
    "    scores[word]['text_count'] = text_as_dict[word]\n",
    "    scores[word]['annt_count'] = all_quotes_count_dict[word]    \n",
    "  return scores\n",
    "\n",
    "def display_stats(exp_words, stats):\n",
    "  for word in exp_words:\n",
    "    if stats[word]['annt_count'] != 0 :\n",
    "      word_stat = stats[word]\n",
    "      idf = word_stat['idf']\n",
    "    if stats[word]['annt_freq'] > stats[word]['text_freq'] :\n",
    "      print(\"%20s >>> text-freq = %.5f  quote-freq = \\x1b[31m%.5f\\x1b[0m\"%(word, stats[word]['text_freq'] , stats[word]['annt_freq']))\n",
    "    else:\n",
    "      print(\"%20s >>> text-freq = %.5f  quote-freq = %.5f\"%(word, stats[word]['text_freq'] , stats[word]['annt_freq']))\n",
    "      \n",
    "  print('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text and index utility functions - part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def build_quoted_regions(quoted_parts,randomize = False):\n",
    "    \"\"\"\n",
    "    sort quoted parts, then merge any which overlap or form\n",
    "    continuous quotes\n",
    "\n",
    "    Args :\n",
    "        list of tuples representing sections of text\n",
    "    Returns:\n",
    "        The same but with sections merged to continuous regions where\n",
    "        appropriate\n",
    "    \"\"\"\n",
    "    def purge_list(target_list, remove_list):\n",
    "        for i in reversed(remove_list):\n",
    "            del(target_list[i])\n",
    "        return target_list\n",
    "\n",
    "    remove_list = []\n",
    "    ####  remove any dodgy tuples ####\n",
    "    # check for tuples with start point after stop point, or negative start\n",
    "    for i in range(len(quoted_parts)):\n",
    "        start,stop = quoted_parts[i]\n",
    "        if (start < 0) or (start > stop):\n",
    "            print(\"warning - start point should be non-negative and not greater than stop point in \", quoted_parts[i])\n",
    "            remove_list.append(i)\n",
    "    # for i in reversed(remove_list):\n",
    "    #     del(quoted_parts[i])\n",
    "    purge_list(quoted_parts,remove_list)\n",
    "\n",
    "    #### main sort and merge ####\n",
    "    quoted_parts = sorted(quoted_parts)\n",
    "    quoted_parts_len = len(quoted_parts)\n",
    "    remove_list = []\n",
    "    for i in range(quoted_parts_len - 1):\n",
    "        # compare end of one part with start of other - merge if overlap\n",
    "        start1, stop1 = quoted_parts[i]\n",
    "        start2, stop2 = quoted_parts[i + 1]\n",
    "        if stop1 >= start2:\n",
    "            if stop2 <= stop1:\n",
    "                # remove subsumed part\n",
    "                remove_list.append(i+1)\n",
    "            else:\n",
    "                # second part absorbs first, first is removed\n",
    "                quoted_parts[i + 1] = (start1, stop2)\n",
    "                remove_list.append(i)\n",
    "    purge_list(quoted_parts,remove_list)\n",
    "\n",
    "    return quoted_parts\n",
    "  \n",
    "def randomize_regions(quoted_parts,text_len):\n",
    "  \"\"\"\n",
    "  Takes some quoted regions and returns randomized control regions of \n",
    "  the same length and number\n",
    "  \"\"\"\n",
    "  num_regions = len(quoted_parts)\n",
    "  num_rand_regions = 0 \n",
    "  rand_regions = []\n",
    "  attempts = 0\n",
    "  while (num_rand_regions < num_regions) and (attempts < 100):\n",
    "    start = random.randint(0,text_len-1)\n",
    "    (quote_start,quote_stop) = quoted_parts[num_rand_regions]\n",
    "    region_len = quote_stop - quote_start \n",
    "    stop = start + region_len \n",
    "    print(start,stop)\n",
    "    if  stop > text_len - 1 :\n",
    "      attempts += 1 \n",
    "      continue\n",
    "    else:\n",
    "      overlap = False\n",
    "      for i in range(num_rand_regions):\n",
    "        if (start in rand_regions[i]) or (stop in rand_regions[i]):\n",
    "          overlap = True\n",
    "          continue\n",
    "#   if there's an overlap don't keep this region , find a new one \n",
    "      if overlap:\n",
    "        continue\n",
    "      else:\n",
    "        rand_regions.append((start,stop))\n",
    "        num_rand_regions += 1\n",
    "  return rand_regions\n",
    "        \n",
    "##############################\n",
    "\n",
    "def get_quote_idxs(txt, quotes, err_file = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        txt - string\n",
    "        quotes - list of string\n",
    "    Returns:\n",
    "        list of tuples indicating (start,stop) position of each quote in txt (if doesn't appear it's ignored)\n",
    "    \"\"\"\n",
    "    quoted_idxs = []\n",
    "    for quote in quotes:\n",
    "      start = txt.find(quote)\n",
    "      if start != -1 :\n",
    "        quoted_idxs.append((start,start+len(quote)))\n",
    "      else:\n",
    "        if err_file is not None:\n",
    "          err_file.write(\"\\n*START OF TEXT*\\n\")\n",
    "          err_file.write(txt)\n",
    "          err_file.write(\"\\n\")\n",
    "          err_file.write(\"** END OF TEXT*\\n\")\n",
    "          err_file.write(\"quote = \")\n",
    "          err_file.write(quote)\n",
    "          err_file.write(\"\\n***\\n\")\n",
    "        \n",
    "    return quoted_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         quote\n",
      "0     lazy dog\n",
      "1  jumped over\n",
      "text dictionary\n",
      "Counter({'rhubarb': 52, 'dog': 3, 'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumped': 1, 'over': 1, 'lazy': 1, 'more': 1, 'rhubarbrhubarb': 1})\n",
      "quote region [(20, 31), (36, 44)]\n",
      "{'dog': {'annt_count': 1, 'text_count': 3, 'weight': 0.4}, 'rhubarb': {'annt_count': 0, 'text_count': 52, 'weight': 0.2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "# test code \n",
    "\n",
    "col_names =  ['quote']\n",
    "quotes_df  = pd.DataFrame(columns = col_names)\n",
    "# my_df\n",
    "# If you want to add a record to the dataframe it would be better to use:\n",
    "\n",
    "# quotes_df.loc[len(my_df)] = [\"lazy dog\"]\n",
    "quotes_df.loc[0] = [\"lazy dog\"]\n",
    "quotes_df.loc[1] = [\"jumped over\"]\n",
    "# quotes_df.loc[1] = [\"quick fox\"]\n",
    "print(quotes_df)\n",
    "\n",
    "text = 'the quick brown fox jumped over the lazy dog more dog rhubarb rhubarb dog rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarbrhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb rhubarb'\n",
    "text_dict = Counter(np.array(re.split(r'%s|$' % r'\\W+' , text)))\n",
    "print(\"text dictionary\")\n",
    "print(text_dict)\n",
    "\n",
    "words_list = [(\"dog\",0.4),(\"rhubarb\",0.2)]\n",
    "\n",
    "quotes_list = [quote for quote in quotes_df['quote']]\n",
    "test_quote_idxs = get_quote_idxs(text,quotes_list)\n",
    "\n",
    "\n",
    "quote_region = build_quoted_regions(test_quote_idxs)\n",
    "print(\"quote region\", quote_region)\n",
    "my_score = get_word_scores(words_list, text, text_dict, quote_region)\n",
    "print(my_score)\n",
    "\n",
    "\n",
    "# display_stats(words,my_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sorted list of individual page__id's\n",
    "page_id_set = set(testing['page__id'])\n",
    "page_id_list = list(page_id_set)\n",
    "page_id_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page id =  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:21:50.180316\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"t obama a s a nutritional s nutritional nutritional obama obama obama a obamas i called i s t t s...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:21:50.181223\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"t obama a s a s now obama obama obama a unappetizing obamas i i s t t s...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:21:50.182588\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"t obama a s a s obama obama obama a obamas i i s t t s...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:21:50.185688\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"t how change geez obama a s hit a replied s republicans republicans republicans hit republicans obam...\", \"error\": \"Not understandable English.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-filter 132 2097    citation_needed\n",
      "2098              nasty\n",
      "2099              nasty\n",
      "2100              wrong\n",
      "2101              nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 132 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  133\n",
      "pre-filter 133 2095    citation_needed\n",
      "2096             unfair\n",
      "Name: tag, dtype: object\n",
      "post-filter 133 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  134\n",
      "pre-filter 134 2136    nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 134 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  135\n",
      "pre-filter 135 2093             unfair\n",
      "2094    citation_needed\n",
      "Name: tag, dtype: object\n",
      "post-filter 135 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  136\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:23:10.753841\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"be s be t be be im a s <URL> via s be s <URL>s <URL>s s s t s s a <URL> <URL> <URL> <URL> s t s <URL...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:23:10.754853\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"s t im can can a s <URL> can battery replacements s s <URL>s <URL>s s business s t s s a <URL> us <U...\", \"error\": \"Not understandable English.\"}}\n",
      "pre-filter 136 2084              wrong\n",
      "2085              wrong\n",
      "2086    citation_needed\n",
      "2087              nasty\n",
      "2088              nasty\n",
      "2089    citation_needed\n",
      "2090    citation_needed\n",
      "2091    citation_needed\n",
      "2092              nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 136 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  137\n",
      "pre-filter 137 2080    unfair\n",
      "2081    unfair\n",
      "2082    unfair\n",
      "2083     nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 137 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  138\n",
      "pre-filter 138 2066             unfair\n",
      "2067              nasty\n",
      "2068              nasty\n",
      "2069              nasty\n",
      "2070              nasty\n",
      "2071              nasty\n",
      "2072              nasty\n",
      "2073              wrong\n",
      "2074    citation_needed\n",
      "Name: tag, dtype: object\n",
      "post-filter 138 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  139\n",
      "pre-filter 139 2075              nasty\n",
      "2076    citation_needed\n",
      "2077              nasty\n",
      "2078    citation_needed\n",
      "2079              wrong\n",
      "Name: tag, dtype: object\n",
      "post-filter 139 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  140\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:24:43.560686\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"clinton a clinton clinton i i clintons clinton found clintons clinton clinton clinton a t t clinton ...\", \"error\": \"Not understandable English.\"}}\n",
      "pre-filter 140 2062     nasty\n",
      "2063    unfair\n",
      "2064     nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 140 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  141\n",
      "pre-filter 141 2134    nasty\n",
      "2135    nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 141 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  142\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:25:43.453114\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"continued a a t s a s man t organized a a a a s a ii a s s media a media no t a catastrophic t ameri...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:25:43.454353\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"trump a a t trump came trumps a trump s trump they t trump a a a a trump trump trumps a a trump s le...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:25:43.455150\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"trump a could a past t trump replied trumps ready a trump s trump t trump a a a a trump trump trumps...\", \"error\": \"Not understandable English.\"}}\n",
      "pre-filter 142 2133    wrong\n",
      "Name: tag, dtype: object\n",
      "post-filter 142 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  143\n",
      "pre-filter 143 2130              nasty\n",
      "2131              wrong\n",
      "2132    citation_needed\n",
      "Name: tag, dtype: object\n",
      "post-filter 143 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  144\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:26:44.829104\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"trump trump trump you you trump you trump s you you you a a member you i a d a t s s a trump a s you...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:26:44.830721\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"you you you s you you you a put a you i a d a t s as s a a s as as you t you you you even you t s ev...\", \"error\": \"Not understandable English.\"}}\n",
      "pre-filter 144 2055     nasty\n",
      "2056     nasty\n",
      "2057     wrong\n",
      "2058     nasty\n",
      "2059     nasty\n",
      "2060    unfair\n",
      "Name: tag, dtype: object\n",
      "post-filter 144 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-filter 145 2050              wrong\n",
      "2051    citation_needed\n",
      "2052    citation_needed\n",
      "2053    citation_needed\n",
      "Name: tag, dtype: object\n",
      "post-filter 145 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  146\n",
      "pre-filter 146 2044    unfair\n",
      "2045    unfair\n",
      "2046     nasty\n",
      "2047     nasty\n",
      "2048     nasty\n",
      "2049     wrong\n",
      "Name: tag, dtype: object\n",
      "post-filter 146 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  147\n",
      "pre-filter 147 2038     wrong\n",
      "2039     wrong\n",
      "2040     nasty\n",
      "2041    unfair\n",
      "2042    unfair\n",
      "2043     nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 147 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  148\n",
      "pre-filter 148 2122    nasty\n",
      "2123    nasty\n",
      "2124    nasty\n",
      "2125    nasty\n",
      "2126    nasty\n",
      "2127    nasty\n",
      "2128    nasty\n",
      "2129    nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 148 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  149\n",
      "pre-filter 149 2119              nasty\n",
      "2120              nasty\n",
      "2121    citation_needed\n",
      "Name: tag, dtype: object\n",
      "post-filter 149 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  150\n",
      "pre-filter 150 2028              nasty\n",
      "2029    citation_needed\n",
      "2030              nasty\n",
      "2031              nasty\n",
      "2032              nasty\n",
      "2033              nasty\n",
      "2034              nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 150 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  151\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:29:53.025641\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"obama obama is a a a <URL> <DIGIT> isnt s is sums <DIGIT> s <DIGIT> t a <DIGIT> a <DIGIT> is...\", \"error\": \"Not understandable English.\"}}\n",
      "{\"level\": \"WARNING\", \"message\": \"An error has been found predicting Hyperpartisanship.\", \"log_timestamp\": \"2018-09-07 09:29:53.026655\", \"filename\": \"hyperpartisanship_predictor.py\", \"function\": \"filter_results\", \"path\": \"/Users/rick/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\", \"logger_name\": \"factnlp\", \"lineno\": 85, \"process\": 46898, \"thread\": 140736053298048, \"details\": {\"message\": \"An error has been found predicting Hyperpartisanship.\", \"stage\": \"bias_predict_error\", \"text\": \"it obama obama a a a t <DIGIT> t kissing s democrats perfectly <DIGIT> s made <DIGIT> t a <DIGIT> a ...\", \"error\": \"Not understandable English.\"}}\n",
      "pre-filter 151 2035    unfair\n",
      "2036     nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 151 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  152\n",
      "pre-filter 152 2024     wrong\n",
      "2025     nasty\n",
      "2026    unfair\n",
      "2027     nasty\n",
      "Name: tag, dtype: object\n",
      "post-filter 152 Series([], Name: tag, dtype: object)\n",
      ">>>  list empty, skip <<<\n",
      "page id =  153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1686b3746157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m#   Run LIME explainer to get explainer words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m   \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_proba_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdebug_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Probability(biased) ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factmata/factnlp-experimental/lime/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    473\u001b[0m         data, yss, distances = self.__data_labels_distances(\n\u001b[1;32m    474\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             distance_metric=distance_metric)\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factmata/factnlp-experimental/lime/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;31m# check for return value from classifier indicating a problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-bc8722d3c28d>\u001b[0m in \u001b[0;36mfm_predict_proba\u001b[0;34m(in_text_list, verbose)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#   call to hyperpartisan classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduction_hp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factmata/factmata-quality-engine/factnlp/factnlp/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_data, text_size, threshold, lang_filter)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/factmata/factmata-quality-engine/factnlp/factnlp/hyperpartisanship/hyperpartisanship_predictor.py\u001b[0m in \u001b[0;36mfilter_results\u001b[0;34m(self, documents, results, threshold)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments_to_categorise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__category_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments_to_categorise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             logger.warning({\n",
      "\u001b[0;32m~/factmata/factmata-quality-engine/factnlp/factnlp/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_data, text_size, threshold, lang_filter)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# Round of probability scores to 3 decimal points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LIME parameters\n",
    "num_features = 10\n",
    "\n",
    "# experiment parameters\n",
    "debug_display = False\n",
    "MIN_TXT_SIZE = 500\n",
    "rand_control_num = 500           # number of times to bootstrap random samples from text\n",
    "num_samples = 5000                # number of samples LIME uses to build its model\n",
    "# =====>\n",
    "stop_words = True                # True - stop words left in ; False - stop words left out \n",
    "\n",
    "num_articles = len(page_id_list)\n",
    "\n",
    "# for speed cache stop words\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def open_results_files(ts):\n",
    "  ts = time.localtime()\n",
    "  results_file = \"results/results_\" + time.strftime(\"%H%M%S_%d%m%Y_withstops.json\", ts)\n",
    "  errors_file = \"results/errors_\" + time.strftime(\"%H%M%S_%d%m%Y.txt\", ts)\n",
    "  try:\n",
    "    fr = open(results_file,'w')\n",
    "  except:\n",
    "    print(\"error opening file %s\" % (results_file))\n",
    "  try:\n",
    "    fe = open(errors_file,'w')\n",
    "  except:\n",
    "    print(\"error opening file %s\" % (errors_file)) \n",
    "  return fr, fe \n",
    "\n",
    "###################################################\n",
    "## CREATE EXPLAINER OBJECT                       ##\n",
    "###################################################\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(split_expression=r'\\W+',class_names=class_names,ngram_size=1,stop_words=stop_words)\n",
    "\n",
    "# def run_experiment(num_articles, num_features,num_samples)\n",
    "# ********** MAIN LOOP *************\n",
    "# look at first [num_articles] pages\n",
    "all_word_scores = []\n",
    "all_random_word_scores = []\n",
    "\n",
    "ts = time.localtime()\n",
    "timestamp =  time.strftime(\"%H%M%S_%d%m%Y\", ts)\n",
    "\n",
    "desc_string = \"500 sets of random words, added word weight from LIME\"\n",
    "short_desc = \"E200 current master version - unigrams, stop words removed; v2 of data\"\n",
    "num_trials = 1\n",
    "\n",
    "\n",
    "#  note - JSON keys have to be strings (unlike python dict keys)\n",
    "experiment_dict = {'timestamp':timestamp,\n",
    "                   'description': desc_string ,\n",
    "                   'short_desc' : short_desc,\n",
    "                     'trials':\n",
    "                       {str(trial):\n",
    "                         {\n",
    "                           'num_articles':num_articles,\n",
    "                           'num_features':num_features,\n",
    "                           'num_samples':num_samples,\n",
    "                           'rand_sample_size':rand_control_num,\n",
    "                           'stop_words': stop_words,\n",
    "                           'corpus':test_file,\n",
    "                           'run_time':'',\n",
    "                           'articles':{}\n",
    "                         }for trial in range(num_trials)\n",
    "                       }\n",
    "                  }\n",
    "# experiment_dict = {'timestamp':timestamp,\n",
    "#                    'description': desc_string ,\n",
    "#                    'short_desc' : short_desc,\n",
    "#                      'trials':\n",
    "#                        {str(trial):\n",
    "#                          {\n",
    "#                            'num_articles':num_articles,\n",
    "#                            'num_features':num_features,\n",
    "#                            'num_samples':num_samples,\n",
    "#                            'rand_sample_size':rand_control_num,\n",
    "#                            'stop_words': stop_words,\n",
    "#                            'corpus':test_file,\n",
    "#                            'run_time':'',\n",
    "#                            'articles':\n",
    "#                              {str(page_id):\n",
    "#                                {\n",
    "#                                'score':0.0,\n",
    "#                                'txt_len':0,\n",
    "#                                'quote_len':0,\n",
    "#                                'explainer_words':[],\n",
    "#                                'random_words':[]\n",
    "#                                } for page_id in page_id_list[:num_articles]                    \n",
    "#                              }\n",
    "#                          }for trial in range(num_trials)\n",
    "#                        }\n",
    "#                   }\n",
    "                    \n",
    "\n",
    "res_file, err_file = open_results_files(ts)\n",
    "\n",
    "\n",
    "page_dict = {}\n",
    "# how many times to select random word comparision set from same text \n",
    "\n",
    "trial_key = str(0)\n",
    "# for page_id in page_id_list[:num_articles]:\n",
    "# for page_id in page_id_list:\n",
    "\n",
    "###################################################\n",
    "## LOOP THROUGH ARTICLES                         ##\n",
    "###################################################\n",
    "for page_id in page_id_list:\n",
    "# for page_id in page_id_list[:2]:\n",
    "  page_key = str(page_id)\n",
    "  print(\"page id = \",page_id)\n",
    "#  get text of article\n",
    "  text = testing[testing['page__id'] == page_id].iloc[0]['text']\n",
    "  text = text.lower()\n",
    "\n",
    "#   skip to next article, if article text is too small\n",
    "  if len(text) < MIN_TXT_SIZE:\n",
    "    continue\n",
    "\n",
    "  #   Run LIME explainer to get explainer words\n",
    "  exp = explainer.explain_instance(text, pred_proba_func, num_features=num_features, num_samples=num_samples)\n",
    "  if debug_display:\n",
    "    print('Probability(biased) =', c.predict_proba([text])[0,0])\n",
    "  # if classifier giving bad result - skip this record\n",
    "  if(exp.classifier_error == True):\n",
    "    print(\"classifier error detected\")\n",
    "    continue\n",
    "  # find all quotes for given article - if none matching criteria, skip this record\n",
    "  quotes_list_df = get_quotes_list(testing, page_id)\n",
    "  if(quotes_list_df.empty):\n",
    "    print(\">>>  list empty, skip <<<\")\n",
    "    continue\n",
    "      \n",
    "  experiment_dict['trials'][trial_key]['articles'][page_key]= {\n",
    "                                                            \n",
    "                                                        'score':0.0,\n",
    "                                                        'txt_len':0,\n",
    "                                                        'quote_len':0,\n",
    "                                                        'explainer_words':[],\n",
    "                                                        'random_words':[]\n",
    "    \n",
    "                                                            }\n",
    "  experiment_dict['trials'][trial_key]['articles'][page_key]['score'] = exp.score\n",
    "  exp_words = [word for (word,weight) in exp.as_list()]\n",
    "\n",
    "\n",
    "  quotes_list = [quote.lower() for quote in quotes_list_df['quote']]\n",
    "  quotes_idxs = get_quote_idxs(text, quotes_list, err_file)\n",
    "  quote_regions = build_quoted_regions(quotes_idxs)\n",
    "  text_as_list = np.array(re.split(r'%s|$' % r'\\W+' , text))\n",
    "  text_count_dict = Counter(text_as_list) \n",
    "                            \n",
    "#   process text into a set of words, removing single character words and stop words (if required)\n",
    "#   print(\"text_as_list = \", text_as_list)\n",
    "  text_as_list = np.array(list(filter(lambda x: len(x)>1, text_as_list)))\n",
    "  text_as_set = set(text_as_list)\n",
    "  if stop_words == False:\n",
    "    text_as_set = set(filter(lambda x: x not in cachedStopWords,text_as_set))  \n",
    "    \n",
    "  text_as_set_list  = np.array(list(text_as_set))\n",
    "    \n",
    "  word_scores = get_word_scores(exp.as_list(), text, text_count_dict, quote_regions )\n",
    "  experiment_dict['trials'][trial_key]['articles'][page_key]['explainer_words'] = word_scores\n",
    "\n",
    "  #   control group of words randomly selected from article    \n",
    "  for i in range(rand_control_num):\n",
    "    all_random_word_scores = []\n",
    "    rand_choice = np.random.choice(text_as_set_list.size, num_features, replace=False)\n",
    "    random_words = [(random,0.0) for random in text_as_set_list[rand_choice]]    \n",
    "    if debug_display:\n",
    "      print(random_words)\n",
    "    random_word_scores = get_word_scores(random_words,text,text_count_dict, quote_regions)\n",
    "    experiment_dict['trials'][trial_key]['articles'][page_key]['random_words'].append(random_word_scores)\n",
    "    \n",
    "json.dump(experiment_dict,res_file)\n",
    "res_file.close()\n",
    "err_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"he\" in cachedStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
